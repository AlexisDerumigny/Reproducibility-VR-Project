---
title: "Analysis of dependence between Tracking loss and UX"
date: "2023-04-19"
output:
  html_document:
    toc: true
    toc_depth: 2
---
This file is for the two hypothesis:
- The trackerloss impacts certain factors of the user experience.
The trackerloss initially was expected to impact intuitiveness, perceived errors, input responsiveness, control, self motion compellingness, and the questions on speed.
From the correlation matrix this was further filtered to only test this for Control and Self motion compellingness, since these seemed to give the largest correlations.

- 





To calculate this correlations, we considered taking the separate questions as random effect, similar to the UX calculation. However since there was no surety that the average of the correlations would give a result with the same meaning as the correlation of the averages, the latter option was chosen since this for sure gave the statistical test desired, although with slightly less statistical power. 
cor((x1 + x2 + x3)/3, y) = correlation between averages
1/3(cor(x1, y) + cor(x2, y) + cor(x3, y)) = average of correlations (would give more statistical power treating subquestions as random effect, but possibly does not answer the question whether one UX group correlates with another on average.)



```{r setup}
#install.packages(c("corrplot", "tidyverse", "knitr"))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dev = 'svg') # set output device to svg
library(tidyverse)
library(lmerTest)
options(width = 150) # https://bookdown.org/yihui/rmarkdown-cookbook/text-width.html
```


# 1- Data loading and preprocessing


```{r}
source("preparingTrackingLossData.R")
source("preparingUXdata.R")
```


```{r}
dataUXTrackingLoss = full_join(
  x = dataTrackingLoss |> select(! all_of("Index")),
  y = dataUX |> mutate(ParticipantID = as.integer(ParticipantID)),
  by = c("ParticipantID", "LocomotionTechnique"),
  suffix = c(".x", ".y"),
  keep = NULL
)
```


# 2- Visualization

```{r}
allQuestionsGroups = unique(data_questions$QuestionGroup)
for (i_QuestionGroup in 1:length(allQuestionsGroups))
{
  nameQuestionGroup = allQuestionsGroups[i_QuestionGroup]
  selectedQuestions = data_questions[
    data_questions$QuestionGroup == nameQuestionGroup, ]
  
  nameQuestions = selectedQuestions$Question_description
  
  df_selectCol = dataUXTrackingLoss[, nameQuestions, drop = FALSE]
  for (i_Question in 1:length(nameQuestions)){
    nameOfQuestion = nameQuestions[i_Question]
    if (selectedQuestions[i_Question, "ToBeInverted"] == 0){
      df_selectCol[, nameOfQuestion] = - abs(3 - df_selectCol[, nameOfQuestion])
    }
  }
  
  dataUXTrackingLoss[, nameQuestionGroup] = rowMeans(df_selectCol)
}
```


```{r, fig.height=12, fig.width=12}
dataUXTrackingLoss$NrTrackerlossesOp = - dataUXTrackingLoss$NrTrackerlosses #invert, so better = less tracker losses

selectedQuestions = c(allQuestionsGroups, "NrTrackerlossesOp",
                      "I think the virtual speed felt natural compared to normal walking",
                      "I wanted to move through the virtual environment")

corMat = cor(dataUXTrackingLoss[, selectedQuestions], use = "pairwise.complete.obs")
corrplot::corrplot(corMat, order = "hclust")
```

```{r, fig.height=10, fig.width=10}
## This further analyzes the correlations in the table above individually. Fill in 2 of your choice, and get data relations between them. These were some plots we made earlier because of an error in the data. We were trying to figure out why some values were unlogically negatively correlated, and checked if this was due to the Simpsons effect, where if and extra variable (aka participant) is not taken into account, the trend will be different. (For each participant it would go upward, while in total it would go downward). This was not the case, and in the end the weird values were caused by a wrong double inversion (therefore not inverting questions that should be inverted).

ggplot(dataUXTrackingLoss) +
  geom_jitter(aes(Satisfaction, Intuitiveness), width = 0.1, height = 0.1)
  
dataUXTrackingLoss |>
  mutate(ParticipantID = factor(ParticipantID)) |>
  ggplot() +
  geom_jitter(aes(Satisfaction, Intuitiveness, color = ParticipantID), width = 0.1, height = 0.1)

dataUXTrackingLoss |>
  mutate(ParticipantID = factor(ParticipantID)) |>
  ggplot() +
  geom_jitter(aes(Satisfaction, Intuitiveness), width = 0.01, height = 0.01) +
  facet_wrap(~ ParticipantID)
  
```


```{r, fig.height=12, fig.width=12}
corTests = dataUXTrackingLoss[, selectedQuestions] |> 
  corrplot::cor.mtest(use = "pairwise.complete.obs")

corrplot::corrplot(corMat, p.mat = corTests$p, sig.level = 0.05, order = "hclust",
                   addrect = 2)
```
```{r}
print(dataUXTrackingLoss$`Self-motion compellingness`)
```


# 3- Modeling

# 3.1- Influence of NrTrackerlosses on Control

```{r}
regtrackUXcor <- lmer(data = dataUXTrackingLoss,
                      Control ~ NrTrackerlosses + 
                        (1 | ParticipantID) + LocomotionTechnique)
summary(regtrackUXcor)
```


# 3.2- Influence of NrTrackerlosses on Self-motion compellingness

```{r}
regtrackUXcor <- lmer(data = dataUXTrackingLoss,
                      `Self-motion compellingness` ~ NrTrackerlosses + 
                        (1 | ParticipantID) + LocomotionTechnique)
summary(regtrackUXcor)
```


# 4. Getting p-values automatically and adjustement of p-values
# do not use anything below, they are for explanation purposes

```{r}
# this would be with a regular linear model with no random effect for the participant, or fixed effect for the locomotion effect. This happens if you draw a line through all datapoints ignoring the participant. There could be a trend per participant and per locomotion technique. If taking these into account, it could be it is not correlated at all. This shows that, since this would be a significant effect, but taking account the participant and locomotion technique (above) it is not. (Do not use this outcome)
regtrackUXcor <- lm(data = dataUXTrackingLoss,
                      `Self-motion compellingness` ~ NrTrackerlosses)
summary(regtrackUXcor)

coef(summary(regtrackUXcor))[2, 4]
coef(summary(regtrackUXcor))["NrTrackerlosses", "Pr(>|t|)"]

# for lmer, it could be that you would use fixef() to get the fixed effects
```


```{r} 
#example of how to perform multiple comparison correction with separate values. However, this is usually not done except if there are many comparisons.
vector_of_pvalues = c(test1 = 0.05, test2 = 0.02, test3 = 0.02455)
p.adjust(vector_of_pvalues, method = "bonferroni")
```


